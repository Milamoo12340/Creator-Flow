import OpenAI from "openai";
import { EvidenceSource, TerminalResponse, TieredTopic } from "./openai";

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

async function fetchResponse(prompt: string, depth: TerminalResponse["depth_level"]): Promise<TerminalResponse> {
  try {
    const response = await client.responses.create({
      model: "gpt-5", // âœ… match your openai.ts choice
      input: prompt,
      max_output_tokens: 600,
    });

    const text = response.output[0].content[0].text;

    return {
      text,
      depth_level: depth,
      sources: [
        {
          type: "ai",
          title: "Generated by OpenAI Responses API",
          date: new Date().toISOString(),
          confidence: 100,
          snippet: text.slice(0, 120) + "...",
        },
      ],
    };
  } catch (err) {
    console.error("fetchResponse fallback error:", err);
    return {
      text: `Fallback ${depth} response.`,
      depth_level: depth,
      sources: [],
    };
  }
}

export async function getTieredTopic(topic: string): Promise<TieredTopic> {
  try {
    const { generateVeritasResponse } = await import("./openai");
    return {
      id: topic.toLowerCase(),
      topic,
      layers: {
        SURFACE: await generateVeritasResponse(`Overview of ${topic}`, "SURFACE"),
        DEEP: await generateVeritasResponse(`Declassified details about ${topic}`, "DEEP"),
        DARK: await generateVeritasResponse(`Suppressed info about ${topic}`, "DARK"),
        VAULT: await generateVeritasResponse(`Classified insights about ${topic}`, "VAULT"),
      },
    };
  } catch (err) {
    console.warn("generateVeritasResponse failed, using fetchResponse fallback:", err);
    return {
      id: topic.toLowerCase(),
      topic,
      layers: {
        SURFACE: await fetchResponse(`Overview of ${topic}`, "SURFACE"),
        DEEP: await fetchResponse(`Declassified details about ${topic}`, "DEEP"),
        DARK: await fetchResponse(`Suppressed info about ${topic}`, "DARK"),
        VAULT: await fetchResponse(`Classified insights about ${topic}`, "VAULT"),
      },
    };
  }
}

export async function getTerminalResponse(prompt: string): Promise<TerminalResponse> {
  try {
    const { generateVeritasResponse } = await import("./openai");
    return await generateVeritasResponse(prompt, "SURFACE");
  } catch {
    return await fetchResponse(prompt, "SURFACE");
  }
}
// mockdata.ts
// Mock Data Fixtures for VERITAS Testing

import { faker } from "@faker-js/faker";

export const mockUser = {
  id: faker.string.uuid(),
  name: faker.person.fullName(),
  email: faker.internet.email(),
};

export const mockConversation = [
  {
    role: "user",
    text: "What is the latest research on quantum computing?",
  },
  {
    role: "assistant",
    text: "According to a 2025 review in Nature, quantum error correction has advanced significantly. [Nature Review](https://www.nature.com/articles/quantum2025)",
    citations: [
      {
        url: "https://www.nature.com/articles/quantum2025",
        title: "Quantum Error Correction Advances (2025)",
      },
    ],
  },
];

export const mockCitations = [
  {
    url: "https://arxiv.org/abs/2506.02097",
    title: "Hybrid AI for Responsive Multi-Turn Online Conversations",
  },
  {
    url: "https://web.archive.org/web/20250101/http://example.com/",
    title: "Archived Example Page",
  },
];
